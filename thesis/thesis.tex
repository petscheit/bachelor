\documentclass[11pt,twoside,a4paper,final]{book}
\usepackage[left=1.6in,right=1.6in,top=1.6in,bottom=1.6in]{geometry}
\usepackage{graphicx}
\usepackage{hyphenat}
\usepackage{todonotes}

\title{zkSwap - Scaling Decentralized Exchanges through Transaction Aggregation}
\author{Paul Etscheit}
\date{March 2021}

\begin{document}

\begin{titlepage}
\maketitle
\end{titlepage}

\section{Introduction}
When being launched in 2015, Ethereum set out to change the way we compute. A trustless, permissionless, and decentralized world computer was envisioned, set to open a new class of applications. The importance of running verifiable, turing-complete code in a permissionless and trustless manner cannot be overstated and enables products and services not thought to be possible. However, the technical limitations have also become apparent quickly. Computations are expensive, theoretical transactions per second are low, and the overall throughput has been stagnant. While Eth2 gives a path towards scaling the network, it is expected to take years to complete. 

The first major use case for Ethereum was tokenization. With the development of the ERC-20 standard, launching a token on the Ethereum blockchain was trivial. As tokens run as smart-contracts on the Ethereum blockchain, they are secured by its proof of work consensus, which, given Ethereums PoW hash rate, makes consensus attacks infeasible. Running on Ethereum blockchain is a significant benefit when looking to tokenize things, as network security can be assumed. While tokenizations are a step in the right direction, they do not come close to the initial vision. While the standardization enables simple integrations into exchanges and wallets, most tokens are isolated in their functionality and ecosystem and lack productive usage.
\todo{token all isolated, not working together... Not a lot of gas needed blabla}

With all of these developments over the past couple of years, it seems we have now entered a new phase of smart-contract use-cases, namely Decentralized Finance (DeFi). While DeFi has many different products and functionalities, at its core aims to utilize tokenized assets in some productive form. Collateralized lending is possible with Aave, yields can be generated by providing assets as liquidity or tokens traded in a non-custodial fashion with Uniswap. It can be questioned how useful or necessary these protocols really are, but the core idea behind them is impressive. Rebuilding traditional financial products, running as non-custodial and permissionless smart-contracts, all based on the same standardizations, has the potential to reshape the way finance works. With these developments not looking to slow down, they are quickly overwhelming the Ethereum blockchain, pushing transaction costs higher and higher. With the DeFi space moving quickly, this is becoming a real hindrance to innovation and is the biggest challenge Ethereum is currently facing. 

With longer-term scaling solutions in development, several shorter-term approaches have been proposed. While these do differ, they all aim to move transactional data to a layer-2\footnote{A layer-2 system is a data storage that is not on the blockchain but has its state committed to it some way} system, ensuring correctness of that data in some way. One of the approaches is called zk-rollup, the focus of this work. Moving data to a layer-2 system can increase the number of transactions that fit into a block, while also reducing transaction costs for the user. Currently, the most used smart-contract is the Uniswap router, which handles all Uniswap trades. To date, it has accrued \$290m in transaction fees and makes up around 15\% of a block's gas limit, putting strain on the Ethereum network. With rising gas prices, performing Uniswap trades has also become prohibitively expensive. This work will explore how zk-rollups can be used to aggregate Uniswap trades to reduce on-chain transactions while ensuring correctness with a zkSNARK proof. This could be a useful scaling technique, as it reduces strain on the network while at the same time reducing transaction fees for users.


% Essentially, we are looking for ways to compress the amount of data

% The efficiency of a smart-contract is mainly defined by the amount of gas used for transactions to be executed. As these smart-contracts run on a distributed network with limited processing power, these executions must be paid for by the sender of a transaction with gas. As there is a limit to how much gas can be used per block, reducin


% \section{Background}
% good idea for introducing gas as power/efficiency metric

% When discussing scaling, gas is a good metric to look at. Every block in Ethereums blockchain has a gas limit that can't be oversteped, \todo{check this, miners should be able to seal blocks still i think} so its a good indicator of proccessing power of the network. At the same time, transactions with smart-contracts use an amount of gas for there execution. The amount of gas needed is defined by the opcodes used for that transaction, which have a fixed price. In that sense, a smart-contracts efficiency can be defined by the amount of gas needed for a transaction. 

% As with all computer systems, scaling can be achived by increasing processing power. Increasing the processing power of a distributed system however, is a complex process. Given that the system is optimized, the only real approach to increasing processing power is sharding. Conceptually, sharding can be seen as upgrading to a multi-core CPU. We seperate the network into individual shards, not requiring every node to proccess every transaction, thereby increasing the processing power of the entire network. Transitioning to a sharded network, namely Eth2, is a highly complex process expected to take years to complete. While this is an inevitable step, aimed at increasing the networks processing power, it wont help in scaling the network for the next couple of years. Shorter term solutions are needed. 

% Another approach for scaling is increasing a smart-contracts efficiency. As in traditional software applications, reducing the computational cost per operation will in general increase our throughput. In smart-contracts this can be achived by reducing the amount of gas needed for a executing a transaction. As every block has a maximum amount of gas that can be proccessed, reducing it will result in an increased amount of transactions to be proccessed in that block. In smart-contracts data-storage is very expensive. To reduce cost


\bibliographystyle{splncs04}
\bibliography{mybibliography}
\end{document}
